{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "video_game_classify.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "PmBZaRnGq-_p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Introduction**\n",
        "\n",
        "This ipython notebook file downloads the video game genre data from the github repo and trains on it to predict from video game images what possible class the image belongs to. \n",
        "\n",
        "The classes here are: FPS, RTS and SPT\n",
        "\n",
        "FPS- First Person Shooter\n",
        "RTS- Real Time Strategy\n",
        "SPT- Sports"
      ]
    },
    {
      "metadata": {
        "id": "nBkTH1NjtUBV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Get Data**\n",
        "\n",
        "Getting the data by cloning the already prepared data from github.\n",
        "\n",
        "There is a python script available to data scrap from youtube and convert it into images."
      ]
    },
    {
      "metadata": {
        "id": "sawHWB76F7Ju",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "38bf37ca-0b99-4c06-a00f-3da65421537b"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/GuruShiva/video_game_genre_data.git"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'video_game_genre_data'...\n",
            "remote: Enumerating objects: 2953, done.\u001b[K\n",
            "remote: Total 2953 (delta 0), reused 0 (delta 0), pack-reused 2953\u001b[K\n",
            "Receiving objects: 100% (2953/2953), 1.62 GiB | 37.29 MiB/s, done.\n",
            "Resolving deltas: 100% (34/34), done.\n",
            "Checking out files: 100% (3154/3154), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0pX30A5muCST",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Check Data**\n",
        "\n",
        "To make sure the data has been gathered."
      ]
    },
    {
      "metadata": {
        "id": "1Gvc4xfZP43_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fd3253d8-aa2a-4ac5-d62d-c7f9cfc3da45"
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "%cd video_game_genre_data/\n",
        "!ls"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "video_game_genre_data\n",
            "/content/video_game_genre_data\n",
            "data  extract_frame_genric.py  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dPArsVggSwr9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Load Dependencies**\n",
        "\n",
        "Import the keras dependencies, numpy and os files\n"
      ]
    },
    {
      "metadata": {
        "id": "EPBJWUMAQDe9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# data augmenting / preprocessing\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "# model architecture and training\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "# GPU check\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "# displaying images in notebook\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# finding files\n",
        "import os\n",
        "\n",
        "# array stuff\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W1BMeamqVucC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Data Augmentation Techniques**\n",
        "\n",
        "* Augmenting input images by making small changes, increases the number, and diversity, of input images. This will increase the model's probability of learning the correct image features\n",
        "\n",
        "* Below follows a visual example of how images can be augmented. Keras will take care of this during training (we aren't going to use these example images during training)."
      ]
    },
    {
      "metadata": {
        "id": "vpvfHdMSmhzH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir data/transform_samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1eWi24CwmsSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c1bafd66-87eb-46dd-cb9b-5f27780034f4"
      },
      "cell_type": "code",
      "source": [
        "# augmentation specs\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "# original image\n",
        "img = load_img('data/images/train/FPS/FPS11000.jpg')\n",
        "\n",
        "# convert image to Numpy array (numeric value representation of image)\n",
        "x = img_to_array(img)\n",
        "print(\"Image Shape: {}\".format(x.shape))\n",
        "\n",
        "# reshape for Keras use\n",
        "x = x.reshape((1,) + x.shape)\n",
        "print(\"Image Shape: {}\".format(x.shape))\n",
        "\n",
        "\n",
        "# the .flow() command below generates batches of randomly transformed images\n",
        "# and saves the results to the `data/transform_samples/` directory\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=1,\n",
        "                          save_to_dir='data/transform_samples', save_prefix='FPS', save_format='jpeg'):\n",
        "    i += 1\n",
        "    if i > 3:\n",
        "        break  # otherwise the generator would loop indefinitely"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image Shape: (1080, 1920, 3)\n",
            "Image Shape: (1, 1080, 1920, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7M89GOHIvQ6J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Creating Model Architecture**"
      ]
    },
    {
      "metadata": {
        "id": "I6ldbT1pUGH6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fully connected model (opposed to model with different input / branches)\n",
        "model = Sequential()\n",
        "\n",
        "# input and first hidden layer\n",
        "# - 2D images (Conv2D - https://keras.io/layers/convolutional/#conv2d)\n",
        "# - 32 filters applied to input images (meaning 32 outputs per image)\n",
        "# - filter/kernel has size (3x3)\n",
        "# - strides is by default (1,1), meaning the filter moves one pixel at a time (both directions)\n",
        "# - padding is by default 'valid', meaning if the image doesn't meet input shape, padding will be added\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(164, 164, 3)))\n",
        "# activation function (ensures non-linearity)\n",
        "model.add(Activation('relu'))\n",
        "# max pooling reduces dimensionality\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# second hidden layer\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# third hidden layer\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# the model so far outputs 3D feature maps (height, width, features)\n",
        "# now we need to flatten it to allow computation\n",
        "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
        "\n",
        "# a normal 1D hidden layer with less neurons (not necessary)\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# dropout removes influence of neurons that don't add value\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# output layer (2 neurons) (bug with binary - now matching num of classes - https://github.com/keras-team/keras/issues/6499)\n",
        "# this will give us our 'probability' value\n",
        "model.add(Dense(3))\n",
        "\n",
        "# change to a value between 0 and 1\n",
        "model.add(Activation('softmax')) # binary bug (binary use 'sigmoid')\n",
        "\n",
        "# model training configuration (https://keras.io/models/model/)\n",
        "# loss function - binary crossentropy - ideal for 2 classes # bug - https://github.com/keras-team/keras/issues/6499\n",
        "# optimizer - rmsprop (http://ruder.io/optimizing-gradient-descent/index.html#rmsprop) - for gradient descent (finding best weights)\n",
        "# metrics - accuracy (proportion of correrctly classified images over number of total images)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='Adam', # rmsprop\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_WpB-QMXwiXN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Data Preparation / Augmentation**"
      ]
    },
    {
      "metadata": {
        "id": "DE25a3RtUPhP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "207f4b54-e31a-4eff-fb55-82e2b754cc14"
      },
      "cell_type": "code",
      "source": [
        "# number of images fed into CNN at a time\n",
        "# not too big - will take forever to train\n",
        "# not too small - model will struggle to get a good idea of \n",
        "# the classes in general\n",
        "batch_size = 500\n",
        "\n",
        "# augment settings for training data\n",
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255, #RGB colours (change values to 0 to 1)\n",
        "        shear_range=0.2, #tilt random images (20% of images)\n",
        "        zoom_range=0.2, # zoom random iamges (20% of images)\n",
        "        horizontal_flip=True) # flip images\n",
        "\n",
        "# augment settings for validation data\n",
        "# this is the augmentation configuration we will use for validation:\n",
        "# only rescaling\n",
        "validate_datagen = ImageDataGenerator(rescale=1./255) #RGB colours (change values to 0 to 1)\n",
        "\n",
        "# this is a generator that will read pictures found in\n",
        "# subfolers of 'data/train', and indefinitely generate\n",
        "# batches of augmented image data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'data/images/train',  # this is the target directory\n",
        "        target_size=(164, 164),  # all images will be resized to 164x164 (same as input shape in architecture)\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')  # bug with binary - https://github.com/keras-team/keras/issues/6499- since we use binary_crossentropy loss, we need binary labels\n",
        "\n",
        "# this is a similar generator, for validation data\n",
        "validation_generator = validate_datagen.flow_from_directory(\n",
        "        'data/images/validate',\n",
        "        target_size=(164, 164),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical') # bug with 'binary' - https://github.com/keras-team/keras/issues/6499"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2424 images belonging to 3 classes.\n",
            "Found 597 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jaWi1N2RwxlJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Model Training**"
      ]
    },
    {
      "metadata": {
        "id": "aQMTuIwqUkPI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "da7051b0-7911-4919-8755-a7ee7daa2ad1"
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=2000 // batch_size, # total number of images processed is batch_size*steps_per_epoch*epochs\n",
        "        epochs=10,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=800 // batch_size)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 126s 31s/step - loss: 0.1146 - acc: 0.9662 - val_loss: 0.1155 - val_acc: 0.9560\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 99s 25s/step - loss: 0.1036 - acc: 0.9652 - val_loss: 0.1105 - val_acc: 0.9620\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 102s 25s/step - loss: 0.1132 - acc: 0.9600 - val_loss: 0.1101 - val_acc: 0.9620\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 95s 24s/step - loss: 0.1145 - acc: 0.9651 - val_loss: 0.1127 - val_acc: 0.9600\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 102s 25s/step - loss: 0.1069 - acc: 0.9670 - val_loss: 0.1158 - val_acc: 0.9620\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 99s 25s/step - loss: 0.1024 - acc: 0.9644 - val_loss: 0.1133 - val_acc: 0.9620\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 102s 25s/step - loss: 0.1046 - acc: 0.9710 - val_loss: 0.1092 - val_acc: 0.9640\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 99s 25s/step - loss: 0.1135 - acc: 0.9631 - val_loss: 0.1084 - val_acc: 0.9620\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 95s 24s/step - loss: 0.0850 - acc: 0.9718 - val_loss: 0.1105 - val_acc: 0.9640\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 103s 26s/step - loss: 0.1102 - acc: 0.9645 - val_loss: 0.1058 - val_acc: 0.9660\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe88260bc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "DRsdtJF9w33O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Classifying Unseen Data**"
      ]
    },
    {
      "metadata": {
        "id": "29m85mToZ-KK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "eea6a6b8-a634-4fa4-ee9d-6be32bca6358"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "\n",
        "test_generator = datagen.flow_from_directory(\n",
        "        'data/images/test/SPT', # never seen before images - IMPORTANT - still needs subfolder(s)\n",
        "        target_size=(164, 164), # same as input shape\n",
        "        batch_size=batch_size, # number of images going in at the same time\n",
        "        class_mode='categorical',  # this means our generator will only yield batches of data, no labels\n",
        "        shuffle=False)  # our data will be in order, 5 cats then 5 dogs\n",
        "\n",
        "# bug fix workaround - https://towardsdatascience.com/keras-a-thing-you-should-know-about-keras-if-you-plan-to-train-a-deep-learning-model-on-a-large-fdd63ce66bd2\n",
        "predictions = model.predict_generator(test_generator)\n",
        "predictions = np.argmax(predictions, axis=-1) #multiple categories\n",
        "label_map = (train_generator.class_indices)\n",
        "label_map = dict((v,k) for k,v in label_map.items()) #flip k,v\n",
        "predictions = [label_map[k] for k in predictions]\n",
        "\n",
        "print(predictions)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 52 images belonging to 1 classes.\n",
            "['SPT', 'FPS', 'SPT', 'SPT', 'SPT', 'RTS', 'SPT', 'SPT', 'SPT', 'SPT', 'RTS', 'SPT', 'FPS', 'SPT', 'SPT', 'SPT', 'SPT', 'SPT', 'SPT', 'SPT', 'FPS', 'SPT', 'SPT', 'SPT', 'SPT', 'SPT', 'SPT', 'SPT', 'SPT', 'FPS', 'SPT', 'SPT', 'SPT', 'SPT', 'SPT', 'SPT', 'SPT', 'SPT', 'SPT', 'SPT', 'SPT', 'SPT', 'SPT', 'SPT', 'SPT', 'SPT', 'SPT', 'RTS', 'SPT', 'SPT', 'SPT', 'SPT']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}